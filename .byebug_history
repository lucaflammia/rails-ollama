c
params
c
q
params
c
params
c
self.q_and_a.last
self.q_and_a.last.
self.q_and_a.last.last
self.q_and_a.last
self.q_and_a
response_raw
response
c
response
c
params
Chat
c
chat_params
c
message
response[0].message.content
response[0].message
self.q_and_a
c
self.q_and_a
c
q
response[0].message.content
response[0].message
response.class
response.last
response.message
response
c
message.last[:content]
message.last[:role]
message.last["role"]
message
message[:content]
c
message
q
raw
event
message
c
stream_proc(message, event)
c
q
messages
messages.last
c
messages.last
c
messages.last
q
messages
messages.last
messages.last['role']
c
messages.last['role']
messages.last
messages
q
message[:content]
message
new_content
message["content"]
q
message["content"]
message["content"] + new_content
message.content
message
event
new_content
c
messages.last["role"]
messages.last.role
messages.last
c
q
messages.map {|m| {role: m["role"], content: m["content"]}}
messages.map {|m| {role: m["role], content: m[:content]}}
messages.map {|m| {role: m[:role], content: m[:content]}}
messages.map {|m| print m}
messages.map {|m| {role: m.role, content: m.content}}
c
self.history
history
c
client.chat(parameters: {model:"gpt-3.5-turbo", messages:})
client.chat(parameters: {model:"gpt-3.5-turbo", messages:}
client.chat(parameters: {model:"gpt-3.5-turbo", messages: messages)
client.chat(parameters: {model:"gpt-3.5-turbo", messages:)
messages
client.chat(parameters: {model:"gpt-3.5-turbo", messages: [{'role': 'system', 'content': ['']}, {'role': 'user', content: ['hi']}]})
client.chat(parameters: {model:"gpt-3.5-turbo", messages: [{'role': 'system', 'content': []}, {'role': 'user', content: ['hi']}]})
client.chat(parameters: {model:"gpt-3.5=-turbo", messages: [{'role': 'system', 'content': []}, {'role': 'user', content: ['hi']}]})
client.chat(parameters: {model:"gpt-3.5=-turbo", messages: ['hi']})
client
